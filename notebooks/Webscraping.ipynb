{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\gaura\\anaconda3\\envs\\ai_project\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\gaura\\anaconda3\\envs\\ai_project\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgramScraper:\n",
    "    def __init__(self, base_url):\n",
    "        self.base_url = base_url\n",
    "\n",
    "    def scrape_multiple_programs(self, program_ids):\n",
    "            results = []\n",
    "            for program_id in program_ids:\n",
    "                print(f\"Scraping details for Program ID: {program_id}\")\n",
    "                details = self.scrape_program_details(program_id)\n",
    "                results.append(details)\n",
    "            return results\n",
    "\n",
    "    def scrape_program_details(self, program_id):\n",
    "        url = self.base_url.format(id=program_id)\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Extract Description/Content\n",
    "            description = soup.find(\"dt\", class_=\"c-description-list__content\", string=\"Description/content\")\n",
    "            description_text = description.find_next(\"dd\").get_text(strip=True) if description else \"\"\n",
    "\n",
    "            # Extract Course Organisation\n",
    "            course_org = soup.find(\"dt\", class_=\"c-description-list__content\", string=\"Course organisation\")\n",
    "            course_org_text = course_org.find_next(\"dd\").get_text(strip=True) if course_org else \"\"\n",
    "\n",
    "            return {\n",
    "                \"id\": program_id,\n",
    "                \"Description/content\": description_text,\n",
    "                \"Course Organisation\": course_org_text\n",
    "            }\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching data from API: {e}\")\n",
    "            return None\n",
    "\n",
    "    def save_to_json(self, data, file_path):\n",
    "\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok= True)\n",
    "\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "        print(f\"Data saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping details for Program ID: 8305\n",
      "Scraping details for Program ID: 4439\n",
      "Scraping details for Program ID: 4870\n",
      "Scraping details for Program ID: 5616\n",
      "Scraping details for Program ID: 4455\n",
      "Scraping details for Program ID: 4591\n",
      "Scraping details for Program ID: 7606\n",
      "Scraping details for Program ID: 8324\n",
      "Scraping details for Program ID: 9856\n",
      "Scraping details for Program ID: 3629\n",
      "Scraping details for Program ID: 4249\n",
      "Scraping details for Program ID: 4238\n",
      "Scraping details for Program ID: 5551\n",
      "Scraping details for Program ID: 8935\n",
      "Scraping details for Program ID: 3736\n",
      "Scraping details for Program ID: 8900\n",
      "Scraping details for Program ID: 5245\n",
      "Scraping details for Program ID: 7670\n",
      "Scraping details for Program ID: 7744\n",
      "Scraping details for Program ID: 3981\n",
      "Scraping details for Program ID: 4700\n",
      "Scraping details for Program ID: 3624\n",
      "Scraping details for Program ID: 9042\n",
      "Scraping details for Program ID: 7618\n",
      "Scraping details for Program ID: 9673\n",
      "Scraping details for Program ID: 8936\n",
      "Scraping details for Program ID: 4490\n",
      "Scraping details for Program ID: 4842\n",
      "Scraping details for Program ID: 4239\n",
      "Scraping details for Program ID: 8440\n",
      "Scraping details for Program ID: 3827\n",
      "Scraping details for Program ID: 4092\n",
      "Scraping details for Program ID: 9725\n",
      "Scraping details for Program ID: 4686\n",
      "Scraping details for Program ID: 4660\n",
      "Scraping details for Program ID: 3727\n",
      "Scraping details for Program ID: 5202\n",
      "Scraping details for Program ID: 3903\n",
      "Scraping details for Program ID: 9040\n",
      "Scraping details for Program ID: 6236\n",
      "Scraping details for Program ID: 6296\n",
      "Scraping details for Program ID: 8953\n",
      "Scraping details for Program ID: 8353\n",
      "Scraping details for Program ID: 7124\n",
      "Scraping details for Program ID: 5576\n",
      "Scraping details for Program ID: 4521\n",
      "Scraping details for Program ID: 4384\n",
      "Scraping details for Program ID: 7708\n",
      "Scraping details for Program ID: 3696\n",
      "Scraping details for Program ID: 7658\n",
      "Scraping details for Program ID: 6529\n",
      "Scraping details for Program ID: 7636\n",
      "Scraping details for Program ID: 7660\n",
      "Scraping details for Program ID: 3960\n",
      "Scraping details for Program ID: 4556\n",
      "Scraping details for Program ID: 9077\n",
      "Scraping details for Program ID: 9691\n",
      "Scraping details for Program ID: 3739\n",
      "Scraping details for Program ID: 8429\n",
      "Scraping details for Program ID: 4350\n",
      "Scraping details for Program ID: 5253\n",
      "Scraping details for Program ID: 9858\n",
      "Scraping details for Program ID: 6937\n",
      "Scraping details for Program ID: 4001\n",
      "Scraping details for Program ID: 3877\n",
      "Scraping details for Program ID: 7641\n",
      "Scraping details for Program ID: 9046\n",
      "Scraping details for Program ID: 4581\n",
      "Scraping details for Program ID: 5252\n",
      "Scraping details for Program ID: 4667\n",
      "Scraping details for Program ID: 4886\n",
      "Scraping details for Program ID: 5453\n",
      "Scraping details for Program ID: 4874\n",
      "Scraping details for Program ID: 4427\n",
      "Scraping details for Program ID: 3614\n",
      "Scraping details for Program ID: 4653\n",
      "Scraping details for Program ID: 7784\n",
      "Scraping details for Program ID: 4258\n",
      "Scraping details for Program ID: 9737\n",
      "Scraping details for Program ID: 3667\n",
      "Scraping details for Program ID: 8382\n",
      "Scraping details for Program ID: 9198\n",
      "Scraping details for Program ID: 4343\n",
      "Scraping details for Program ID: 7054\n",
      "Scraping details for Program ID: 8977\n",
      "Scraping details for Program ID: 8518\n",
      "Scraping details for Program ID: 3686\n",
      "Scraping details for Program ID: 4728\n",
      "Scraping details for Program ID: 9770\n",
      "Scraping details for Program ID: 9643\n",
      "Scraping details for Program ID: 4879\n",
      "Scraping details for Program ID: 9776\n",
      "Scraping details for Program ID: 4553\n",
      "Scraping details for Program ID: 9704\n",
      "Scraping details for Program ID: 4775\n",
      "Scraping details for Program ID: 8902\n",
      "Scraping details for Program ID: 9001\n",
      "Scraping details for Program ID: 8417\n",
      "Scraping details for Program ID: 9228\n",
      "Scraping details for Program ID: 4513\n",
      "Scraping details for Program ID: 4225\n",
      "Scraping details for Program ID: 4429\n",
      "Scraping details for Program ID: 4247\n",
      "Scraping details for Program ID: 6140\n",
      "Scraping details for Program ID: 9773\n",
      "Scraping details for Program ID: 7852\n",
      "Error fetching data from API: HTTPSConnectionPool(host='www2.daad.de', port=443): Max retries exceeded with url: /deutschland/studienangebote/international-programmes/en/detail/7852/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001BC989065B0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Scraping details for Program ID: 3632\n",
      "Error fetching data from API: HTTPSConnectionPool(host='www2.daad.de', port=443): Max retries exceeded with url: /deutschland/studienangebote/international-programmes/en/detail/3632/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001BC98EC3820>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Scraping details for Program ID: 7657\n",
      "Error fetching data from API: HTTPSConnectionPool(host='www2.daad.de', port=443): Max retries exceeded with url: /deutschland/studienangebote/international-programmes/en/detail/7657/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001BC98ECC190>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Scraping details for Program ID: 4122\n",
      "Scraping details for Program ID: 9841\n",
      "Scraping details for Program ID: 9709\n",
      "Scraping details for Program ID: 9679\n",
      "Scraping details for Program ID: 7711\n",
      "Scraping details for Program ID: 5561\n",
      "Scraping details for Program ID: 6924\n",
      "Scraping details for Program ID: 9863\n",
      "Scraping details for Program ID: 9646\n",
      "Scraping details for Program ID: 3803\n",
      "Scraping details for Program ID: 9072\n",
      "Scraping details for Program ID: 3728\n",
      "Scraping details for Program ID: 4655\n",
      "Scraping details for Program ID: 9003\n",
      "Scraping details for Program ID: 9223\n",
      "Scraping details for Program ID: 3737\n",
      "Scraping details for Program ID: 8944\n",
      "Scraping details for Program ID: 3923\n",
      "Scraping details for Program ID: 7040\n",
      "Scraping details for Program ID: 3841\n",
      "Scraping details for Program ID: 4634\n",
      "Scraping details for Program ID: 3799\n",
      "Scraping details for Program ID: 7795\n",
      "Scraping details for Program ID: 6119\n",
      "Scraping details for Program ID: 9043\n",
      "Scraping details for Program ID: 5634\n",
      "Scraping details for Program ID: 3862\n",
      "Scraping details for Program ID: 9838\n",
      "Scraping details for Program ID: 4600\n",
      "Scraping details for Program ID: 6262\n",
      "Scraping details for Program ID: 4407\n",
      "Scraping details for Program ID: 9595\n",
      "Scraping details for Program ID: 3724\n",
      "Scraping details for Program ID: 6981\n",
      "Data saved to ../datasets/program_details.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Base URL for scraping\n",
    "    BASE_URL = \"https://www2.daad.de/deutschland/studienangebote/international-programmes/en/detail/{id}/\"\n",
    "\n",
    "    # List of program IDs\n",
    "    PROGRAM_IDS = [\n",
    "    8305, 4439, 4870, 5616, 4455, 4591, 7606, 8324, 9856, 3629,\n",
    "    4249, 4238, 5551, 8935, 3736, 8900, 5245, 7670, 7744, 3981,\n",
    "    4700, 3624, 9042, 7618, 9673, 8936, 4490, 4842, 4239, 8440,\n",
    "    3827, 4092, 9725, 4686, 4660, 3727, 5202, 3903, 9040, 6236,\n",
    "    6296, 8953, 8353, 7124, 5576, 4521, 4384, 7708, 3696, 7658,\n",
    "    6529, 7636, 7660, 3960, 4556, 9077, 9691, 3739, 8429, 4350,\n",
    "    5253, 9858, 6937, 4001, 3877, 7641, 9046, 4581, 5252, 4667,\n",
    "    4886, 5453, 4874, 4427, 3614, 4653, 7784, 4258, 9737, 3667,\n",
    "    8382, 9198, 4343, 7054, 8977, 8518, 3686, 4728, 9770, 9643,\n",
    "    4879, 9776, 4553, 9704, 4775, 8902, 9001, 8417, 9228, 4513,\n",
    "    4225, 4429, 4247, 6140, 9773, 7852, 3632, 7657, 4122, 9841,\n",
    "    9709, 9679, 7711, 5561, 6924, 9863, 9646, 3803, 9072, 3728,\n",
    "    4655, 9003, 9223, 3737, 8944, 3923, 7040, 3841, 4634, 3799,\n",
    "    7795, 6119, 9043, 5634, 3862, 9838, 4600, 6262, 4407, 9595,\n",
    "    3724, 6981\n",
    "]\n",
    "\n",
    "    # Initialize the scraper\n",
    "    scraper = ProgramScraper(BASE_URL)\n",
    "\n",
    "    # Scrape details for all program IDs\n",
    "    scraped_data = scraper.scrape_multiple_programs(PROGRAM_IDS)\n",
    "\n",
    "    # Save the scraped data to a JSON file\n",
    "    scraper.save_to_json(scraped_data, \"../datasets/program_details.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
